{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engines - MovieLens Data\n",
    "\n",
    "## Tuesday June 20 2017\n",
    "\n",
    "MovieLens data sets were collected by the GroupLens Research Project at the University of Minnesota.\n",
    "\n",
    "This data set consists of: * 100,000 ratings (1-5) from 943 users on 1682 movies. * Each user has rated at least 20 movies. * Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "The data was collected through the MovieLens web site (movielens.umn.edu) during the seven-month period from September 19th, 1997 through April 22nd, 1998. This data has been cleaned up - users who had less than 20 ratings or did not have complete demographic information were removed from this data set. Detailed descriptions of the data file can be found at the end of this file.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Load the data into the recommendation format\n",
    "2. Build and assess model accuracy\n",
    "3. Make individual recommendations\n",
    "4. Try multiple models and compare accuracy\n",
    "5. Consider how a company could use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /anaconda/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: numpy>=1.11.2 in /anaconda/lib/python3.6/site-packages (from scikit-surprise)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda/lib/python3.6/site-packages (from scikit-surprise)\r\n"
     ]
    }
   ],
   "source": [
    "# Install Surpise - a useful library for recommendation engines\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Surprise\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Load the data into the recommendation format\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "\n",
    "data = Dataset.load_from_file(file_path = '../../data/u.data', reader=reader)\n",
    "data.split(n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9377\n",
      "MAE:  0.7414\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9395\n",
      "MAE:  0.7431\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9287\n",
      "MAE:  0.7312\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.9301\n",
      "MAE:  0.7330\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.9397\n",
      "MAE:  0.7382\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9352\n",
      "Mean MAE : 0.7374\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "RMSE    0.9377  0.9395  0.9287  0.9301  0.9397  0.9352  \n",
      "MAE     0.7414  0.7431  0.7312  0.7330  0.7382  0.7374  \n"
     ]
    }
   ],
   "source": [
    "# 2. Build and assess model accuracy\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "\n",
    "#Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE']) #Mean Absolute Error\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 2.00   est = 4.26   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# 3. Make individual recommendations\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=2, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9665\n",
      "MAE:  0.7623\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9711\n",
      "MAE:  0.7642\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9608\n",
      "MAE:  0.7544\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.9582\n",
      "MAE:  0.7523\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.9649\n",
      "MAE:  0.7562\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9643\n",
      "Mean MAE : 0.7579\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "RMSE    0.9665  0.9711  0.9608  0.9582  0.9649  0.9643  \n",
      "MAE     0.7623  0.7642  0.7544  0.7523  0.7562  0.7579  \n"
     ]
    }
   ],
   "source": [
    "# 4. Try multiple models and compare accuracy\n",
    "\n",
    "# Try at least 3 of the models mentioned below:\n",
    "\n",
    "#random_pred.NormalPredictor() #Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "#baseline_only.BaselineOnly    Algorithm predicting the baseline estimate for given user and item.\n",
    "#knns.KNNBasic    A basic collaborative filtering algorithm.\n",
    "#knns.KNNWithMeans    A basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "#knns.KNNBaseline    A basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "#matrix_factorization.SVD    The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.\n",
    "#matrix_factorization.SVDpp    The SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "#matrix_factorization.NMF    A collaborative filtering algorithm based on Non-negative Matrix Factorization.\n",
    "#slope_one.SlopeOne    A simple yet accurate collaborative filtering algorithm.\n",
    "#co_clustering.CoClustering    A collaborative filtering algorithm based on co-clustering.\n",
    "\n",
    "# we want the lowest number for RMSE and MAE\n",
    "\n",
    "# Here's how to run Non-Negative Matrix Factorisiation\n",
    "from surprise import NMF\n",
    "\n",
    "# Now we will try Non-Negative Matrix Factorisiation (a form of collaborative filtering)\n",
    "algo.NMF = NMF()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf.NMF = evaluate(algo.NMF, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf.NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NormalPredictor.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 1.5260\n",
      "MAE:  1.2250\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 1.5227\n",
      "MAE:  1.2202\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 1.5256\n",
      "MAE:  1.2214\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 1.5203\n",
      "MAE:  1.2206\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 1.5344\n",
      "MAE:  1.2304\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.5258\n",
      "Mean MAE : 1.2235\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "RMSE    1.5260  1.5227  1.5256  1.5203  1.5344  1.5258  \n",
      "MAE     1.2250  1.2202  1.2214  1.2206  1.2304  1.2235  \n"
     ]
    }
   ],
   "source": [
    "# running the normal predictor Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "from surprise import NormalPredictor\n",
    "\n",
    "# Now we will try Normal Predictor\n",
    "algo.NormalPredictor = NormalPredictor()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf.NormalPredictor = evaluate(algo.NormalPredictor, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf.NormalPredictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm BaselineOnly.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9463\n",
      "MAE:  0.7516\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9476\n",
      "MAE:  0.7523\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9403\n",
      "MAE:  0.7452\n",
      "------------\n",
      "Fold 4\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9409\n",
      "MAE:  0.7442\n",
      "------------\n",
      "Fold 5\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9467\n",
      "MAE:  0.7495\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9444\n",
      "Mean MAE : 0.7485\n",
      "------------\n",
      "------------\n",
      "Evaluating RMSE, MAE of algorithm NormalPredictor.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 1.5267\n",
      "MAE:  1.2273\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 1.5239\n",
      "MAE:  1.2232\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 1.5137\n",
      "MAE:  1.2142\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 1.5199\n",
      "MAE:  1.2210\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 1.5151\n",
      "MAE:  1.2141\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.5199\n",
      "Mean MAE : 1.2200\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "RMSE    0.9463  0.9476  0.9403  0.9409  0.9467  0.9444  \n",
      "MAE     0.7516  0.7523  0.7452  0.7442  0.7495  0.7485  \n"
     ]
    }
   ],
   "source": [
    "#Baseline Model - Algorithm predicting the baseline estimate for given user and item.\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "algo.Baseline = BaselineOnly()\n",
    "\n",
    "perf.BaselineOnly = evaluate(algo.Baseline, data, measures=['RMSE', 'Mae'])\n",
    "\n",
    "perf.NormalPredictor = evaluate(algo.NormalPredictor, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf.BaselineOnly)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9201\n",
      "MAE:  0.7221\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9210\n",
      "MAE:  0.7232\n",
      "------------\n",
      "Fold 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-73db7b2480a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malgo3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVDpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mperf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint_perf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/surprise/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(algo, data, measures, with_dump, dump_dir, verbose)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# train and test algorithm. Keep all rating predictions in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.train (surprise/prediction_algorithms/matrix_factorization.c:5726)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.sgd (surprise/prediction_algorithms/matrix_factorization.c:6983)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/surprise/dataset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#matrix_factorization.SVDpp    The SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "\n",
    "from surprise import SVDpp\n",
    "\n",
    "algo3 = SVDpp()\n",
    "\n",
    "perf.algo3 = evaluate(algo3, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf.algo3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SlopeOne.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9423\n",
      "MAE:  0.7430\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9506\n",
      "MAE:  0.7490\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9437\n",
      "MAE:  0.7413\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.9421\n",
      "MAE:  0.7393\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.9474\n",
      "MAE:  0.7419\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9452\n",
      "Mean MAE : 0.7429\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CaseInsensitiveDefaultDict' object has no attribute 'algo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-31d70bf1c4dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlope_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlopeOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mperf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlope_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlope_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint_perf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlope_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CaseInsensitiveDefaultDict' object has no attribute 'algo'"
     ]
    }
   ],
   "source": [
    "#slope_one.SlopeOne    A simple yet accurate collaborative filtering algorithm.\n",
    "\n",
    "from surprise import SlopeOne\n",
    "\n",
    "algo.Slope_one = SlopeOne()\n",
    "\n",
    "perf.algo.Slope_one = evaluate(algo.Slope_one, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf.algo.Slope_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Consider how a company could use this\n",
    "\n",
    "How might a company use a recommendation like this in practice? Write a few paragraphs covering how they could use the above covering:\n",
    "- How the algorithm works?\n",
    "\n",
    " Each algorithm works in a different way to come up with a predicted rating. For example, the baseline model will assign a rating at random based on a normal distribution of those already existing.\n",
    "\n",
    " SVD++ is similar to SVD but also takes into account implicit ratings. ie did the customer watch the show until the end or did they switch after a short amount of time. It takes computationally a long time (31 min)\n",
    " \n",
    "- What data would be used?\n",
    "- How would we know if it's working?\n",
    "- What is the benefit of using an algorithm over this over just recommending the most popular films overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
